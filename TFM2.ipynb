{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.cidaen.es/assets/img/mCIDaeNnb.png\" alt=\"Logo CiDAEN\" align=\"right\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "<h2><font color=\"#00586D\" size=8>Trabajo Final de Master</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#00586D\" size=5><i>Reto sobre secuenciación de célula única en linajes celulares de cáncer de mama</i></font></h1>\n",
    "\n",
    "<br><br><br>\n",
    "<div align=\"right\">\n",
    "<font color=\"#00586D\" size=3>Alonso Felipe Ruiz</font><br>\n",
    "<font color=\"#00586D\" size=3>Máster en Ciencia de Datos e Ingeniería de Datos en la Nube</font><br>\n",
    "<font color=\"#00586D\" size=3>Universidad de Castilla-La Mancha</font>\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Indice\"></a>\n",
    "<h2><font color=\"#00586D\" size=4>Índice</font></h2>\n",
    "\n",
    "#### <font color=\"#00586D\"> Notebook I</font>\n",
    "* [1. Introducción](#section1)\n",
    "* [2. Preparación de los datos](#section2)\n",
    "* [3. Exploración preliminar](#section3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "style.use('seaborn')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "## <font color=\"#00586D\"> 1. Contexto del proyecto</font>\n",
    "<br>\n",
    "\n",
    "A lo largo de este trabajo de final de master se utilizará una cohorte de datos obtenida a partir de la sequenciación anivel de célula única en lineas celulares de cáncer de mama bajo diferentes tratamientos. Estas lineas celulares han sido caracterizadas a nivel genómico, transcriptómico y proteómico. El juego de datos utilizado para este estudio consta de un análisis por espectometría de masas analizando 67 linajes celulares de cáncer de mama, analizando 3015 condiciones distintas, cuantificando 38 markadores para cada una de ellas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section2\"></a>\n",
    "## <font color=\"#00586D\"> 2. Predicción de valores perdidos</font>\n",
    "<br>\n",
    "El primero de los retos planteados durante el análisis de los datos consiste en la predicción de valores perdidos a partir de los reporteros de las células medidas. La imputación de valores perdidos es esencial en algunos casos, especialmente en el caso de aplicar los conocimientos básicos en clínica. Muchas veces los valores perdidos pueden ser resultado de errores experimentales, pero en otras ocasiones puede deberse a que la implementación de esa medida hace necesario aumentar el coste de la prueba o imposibilita que esta se pueda hacer con equipos convencionales. Este es por ejemplo el caso de la citometría de flujo, donde existen ciertas limitaciones en la técnica que impiden la posibilidad de medir infinitos marcadores al mismo tiempo, además de que aumentar el número de medidas que puedes tomar de manera simultanea, hace requerir de filtros de fluorescencia en el aparato que aumentan enormemente el valor de los mismo.\n",
    "<br>\n",
    "En el caso que nos concierne se imputarán los valores perdidos para los siguientes marcadores:\n",
    "<br>\n",
    "-phospho-ERK:\n",
    "<br>\n",
    "-phospho-Akt(Ser473):\n",
    "<br>\n",
    "-phospho-S6:\n",
    "<br>\n",
    "-phospho-HER2:\n",
    "<br>\n",
    "-phospho-PLCg2:\n",
    "<br>\n",
    "\n",
    "Con ese pretexto se plantea el siguiente reto, centrándose específicamente en 6 tipos celulares distintos:\n",
    "<br>\n",
    "-AU565:\n",
    "<br>\n",
    "-EFM19:\n",
    "<br>\n",
    "-HCC2218: \n",
    "<br>\n",
    "-LY2: \n",
    "<br>\n",
    "-MACLS2:\n",
    "<br>\n",
    "-MDAMB436:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Lectura de los dataframes correspondientes\"\"\"\n",
    "df_goldstandard = pd.read_csv(\"GoldStandards/sc1gold.csv\") #valores reales para analizar la eficacia del modelo\n",
    "df_AU565p = pd.read_csv(\"Single_cell_phospho/Challenge1/AU565.csv\") #datasets de cada subconjunto de células para hacer la predicción\n",
    "df_EFM19p = pd.read_csv(\"Single_cell_phospho/Challenge1/EFM19.csv\")\n",
    "df_HCC2218p = pd.read_csv(\"Single_cell_phospho/Challenge1/HCC2218.csv\")\n",
    "df_LY2p = pd.read_csv(\"Single_cell_phospho/Challenge1/LY2.csv\")\n",
    "df_MACLS2p = pd.read_csv(\"Single_cell_phospho/Challenge1/MACLS2.csv\")\n",
    "df_MDAMB436p = pd.read_csv(\"Single_cell_phospho/Challenge1/MDAMB436.csv\")\n",
    "df_challenge1 = (pd.concat([df_AU565p,df_EFM19p,df_HCC2218p,df_LY2p,df_MACLS2p,df_MDAMB436p]))\n",
    "#selección de las columnas de interés para predecir el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "## <font color=\"#00586D\"> 2.2 Analisis exploratorio y preprocesamiento de los datos. </font>\n",
    "<br>\n",
    "\n",
    "En este apartado analizaremos los datos de partida, su organización y distribución, así como el procesamiento de los datos iniciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = str(\"Single_cell_phospho/complete_cell_lines/*.csv\")\n",
    "filenames = glob.glob(path)\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    dfs.append(pd.read_csv(filename))\n",
    "cell_phospho = pd.concat(dfs, ignore_index=True) #Leer todos los datos de fosforilación para entrenamiento\n",
    "cell_phospho.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las columnas cellID y fileID que no son informativas\n",
    "cell_phospho.drop(['cellID', 'fileID'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de la distribución de las variables a predecir\n",
    "fig, axes = plt.subplots(1,5, figsize=(30,3))\n",
    "variables=[\"p.ERK\", \"p.Akt.Ser473.\", \"p.S6\", \"p.HER2\", \"p.PLCg2\"]\n",
    "for col, ax in enumerate(axes.flatten()):\n",
    "    sns.histplot(data=cell_phospho, x=variables[col], ax=ax)\n",
    "    ax.set_title(variables[col])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_ylabel(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos aquí uno de los primeros problemas que tendremos que intentar solucionar durante el desarrollo del modelo, los valores a predecir de las variables no muestran una distribución normal, además vemos que algunos valores parecen estar sobre representados, también parece haber valores extremos que pueden condicionar la capacidad de predicción del modelo. En el caso de p.HER2 parece que la distribución si es normal y que no hay estos valores sobrerepresentados ni extremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Análisis de las variables discretas\n",
    "fig, axes = plt.subplots(1,3, figsize=(30,3))\n",
    "variables=['cell_line', 'time', 'treatment']\n",
    "for col, ax in enumerate(axes.flatten()):\n",
    "    sns.countplot(data=cell_phospho, x=variables[col], ax=ax)\n",
    "    if col==0:\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=8)\n",
    "    ax.set_title(variables[col])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_ylabel(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos analizar aquí las variables discretas que se utilizarán en el entrenamiento de los datos, podemos observar que hay 44 tipos celulares distintos, que el tiempo transcurre entre 0 y 60 y que hay 6 tipos de tratamiento distintos, vamos a comparar esto con el dataframe de las muestras en las cuales tendremos que predecir los resultados, para hacer frente a cómo vamos a realizar el preprocesamiento de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Análisis de las variables discretas del dataframe que hay que predecir\n",
    "fig, axes = plt.subplots(1,3, figsize=(30,3))\n",
    "variables=['cell_line', 'time', 'treatment']\n",
    "for col, ax in enumerate(axes.flatten()):\n",
    "    sns.countplot(data=df_challenge1, x=variables[col], ax=ax)\n",
    "    if col==0:\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=8)\n",
    "    ax.set_title(variables[col])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_ylabel(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que las lineas celulares son distintas, como sabíamos antes de comenzar el reto, los tratamientos son los mismos y los tiempos concretos la mayoría son los mismos, pero algunos de los presentes en el dataframe de entrenamiento no están presentes en el dataframe que utilizaremos para predecir, esto puede ser un porblema, sobre todo a la hora de que vamos a categorizar la variable tiempo como una variable discreta ordenal, vamos a analizar los datos correspondientes a estos tiempos que solo están presentes en el dataframe cell_phospho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_times=cell_phospho.query(\"time == 12.0 or time == 15.0 or time == 16.0 or time == 25.0 or time == 35.0\")\n",
    "print(f'Los datos correspondientes a tiempos extraños son un total de {len(strange_times)}')\n",
    "print(f'correspondiendo con un {len(strange_times)/len(cell_phospho)*100}% del total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis de estos valores atípicos muestran que 108712 muestras presentan valores en estos tiempos atípicos, solo correspondiendo con un 0.6% de los datos totales de los que disponemos para entrenamiento. Una opción sería eliminarlos y no utilizarlos en el entrenamiento. Pero la opción que vamos a utilizar es sustituir esos datos por el más cercano, por ejemplo, los 12 se sustituiran por 13, los 15 por 14, los 16 por 17, los 25 por 23 y en el caso de los 35, como ya serán un número muy reducido y están justo entre los tiempos 30 y 40, los eliminaremos para evitar aumentar el ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Si no se han procesado el dataframe lo procesa y crea el archivo.\n",
    "if not os.path.isfile(\"cell_phospho.csv\"):\n",
    "    cell_phospho=cell_phospho.replace({12.0: 13.0, 15.0: 14.0, 16.0:17.0, 25.0:23.0})\n",
    "    cell_phospho=cell_phospho.drop(cell_phospho.query(\"time == 35.0\").index)\n",
    "    cell_phospho.to_csv(\"cell_phospho.csv\")\n",
    "# Si se habían procesado anteriormente, y el archivo está disponible, lo lee. \n",
    "else:\n",
    "    cell_phospho=pd.read_csv(\"cell_phospho.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_df_columns = cell_phospho.select_dtypes(exclude=np.number).columns\n",
    "num_df_columns = cell_phospho.select_dtypes(include=np.number).columns\n",
    "#Separamos time que lo utilizaremos como una variable discreta ordinal y las usadas en predicción\n",
    "num_df_columns = num_df_columns.drop([\"time\", \"p.ERK\", \"p.Akt.Ser473.\", \"p.S6\", \"p.HER2\", \"p.PLCg2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analizamos la correlación entre las variables numéricas\n",
    "cell_phospho[num_df_columns].corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que entre muchas de las variables existe una correlación bastante buena, superior a 0.5, eso es bueno y también es comprensible, muchas de estas rutas de señalización se encuentran entrelazadas las unas con las otras y cambios en unas afectarán a las demás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraemos las columnas de los valores que vamos a intentar predecir con el modelo\n",
    "p_ERK=cell_phospho.pop(\"p.ERK\")\n",
    "p_AktSer473=cell_phospho.pop(\"p.Akt.Ser473.\")\n",
    "p_S6=cell_phospho.pop(\"p.S6\")\n",
    "p_HER2=cell_phospho.pop(\"p.HER2\")\n",
    "p_PLCg2=cell_phospho.pop(\"p.PLCg2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este momento podemos comenzar ya con el procesamiento de los datos, para ello vamos a hacer un pipeline de sckitlearn en el que implementemos la transformación de las columnas y la imputación de valores perdidos, antes de nada vamos a analizar qué columnas tienen valores perdidos y cuantos valores perdidos hay en dichas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_phospho.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_phospho.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que no hay 'NaN' en el  dataframe lo cual hace más sencillo el análisis y además vemos que todas las columnas son 'float64' con excepción de treatment y cell_line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''separamos time de las demás variables numéricas ya que la utilizaremos como una variable ordinal, \n",
    "el resto utilizaremos OneHotEncoder. Las variables numéricas las procesaremos como StandardScaler'''\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Lista completa de todas las líneas celulares, tanto las que están en entrenamiento como en predicción\n",
    "cell_lines=[cell_phospho[\"cell_line\"].unique().tolist() + df_challenge1[\"cell_line\"].unique().tolist()]\n",
    "#Lista de tiempos que se usaran en el ensayo\n",
    "time_cat = [[0.0, 5.5, 7.0, 9.0, 13.0, 14.0, 17.0, 18.0, 23.0, 30.0, 40.0, 60.0]]\n",
    "time_transformer = Pipeline([('Ordinal_encoder', OrdinalEncoder(categories=time_cat))])\n",
    "cell_transformer = Pipeline([('onehot_cell', OneHotEncoder(categories=cell_lines))])\n",
    "treatment_transformer = Pipeline([('onehot', OneHotEncoder())])\n",
    "num_transformer = Pipeline([('scaler', StandardScaler())])\n",
    "\n",
    "phospho_trans = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_df_columns),\n",
    "        ('cat', cell_transformer, [\"cell_line\"]),\n",
    "        ('treat', treatment_transformer, [\"treatment\"]),\n",
    "        ('time', time_transformer, ['time'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a proceder a separar los datos de validación y test, lo normal sería aleatorizar las muestras del dataframe para así obtener datos de todas las lineas celulares tanto en el subconjunto de entrenamiento como en el de test, pero, como este modelo está pensado para ser entrenado con los datos de unas lineas celulares y luego utilizarse en el modelado de otras lineas celulares, creo que podría ser una mejor opción, a la hora de no sobreestimar la performance del modelo durante el entrenamiento, separar 7 lineas celulares que se utilizarán para test (aproximadamente el 15% de los datos) y el resto (37 lineas) se utilizarán para entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=(max(cell_phospho.query(\"cell_line == 'HCC1187'\").index) + 1) #7 primeras lineas celulares para test\n",
    "phospho_test=cell_phospho.iloc[:test_size].copy()\n",
    "phospho_train=cell_phospho.iloc[test_size:].copy()\n",
    "\n",
    "#Lo mismo con las sucesivas variables de interes\n",
    "p_ERK_test=p_ERK.iloc[:test_size].copy()\n",
    "p_ERK_train=p_ERK.iloc[test_size:].copy()\n",
    "p_AktSer473_test=p_AktSer473.iloc[:test_size].copy()\n",
    "p_AktSer473_train=p_AktSer473.iloc[test_size:].copy()\n",
    "p_S6_test=p_S6.iloc[:test_size].copy()\n",
    "p_S6_train=p_S6.iloc[test_size:].copy()\n",
    "p_HER2_test=p_HER2.iloc[:test_size].copy()\n",
    "p_HER2_train=p_HER2.iloc[test_size:].copy()\n",
    "p_PLCg2_test=p_PLCg2.iloc[:test_size].copy()\n",
    "p_PLCg2_train=p_PLCg2.iloc[test_size:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque sea más laborioso, se realizarán modelos diferentes para intentar predecir cada una de las variables por separado, así podremos utilizar para cada uno de ellos el acercamiento o el modelo que obtenga mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#00586D\"> 2.3 Modelo predictivo de los niveles de ERK fosforilado. </font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# DataFrame con los resultados\n",
    "results = pd.DataFrame(columns=['Modelo','$R^2$ Entrenamiento','$R^2$ Validación','$R^2$ Test', \n",
    "                                         'MAE Entrenamiento', 'MAE Test']).set_index('Modelo')\n",
    "\n",
    "def show_results(description, model, X_train, y_train, X_test, y_test, is_log=False):\n",
    "    train_r2 = model.score(X_train,y_train)\n",
    "    val_r2 = cross_val_score(model,X_train,y_train,cv=5).mean()\n",
    "    test_r2 = model.score(X_test, y_test)\n",
    "    # Si se utiliza el logaritmo de la variable objetivo hay que \n",
    "    # convertirlo para calcular el error\n",
    "    f = np.exp if is_log else lambda y: y\n",
    "    # Calcula el error    \n",
    "    train_mae = mean_absolute_error(f(y_train), f(model.predict(X_train)))\n",
    "    test_mae = mean_absolute_error(f(y_test), f(model.predict(X_test)))\n",
    "    # Muetra los resultados en formato legible\n",
    "    print('Training \\t\\txValidation \\t\\tTest')\n",
    "    print('-------- \\t\\t----------- \\t\\t----')\n",
    "    print(f\"R\\u00B2 = {train_r2:.3f}\\t\\tR\\u00B2 = {val_r2:.3f}\\t\\tR\\u00B2 = {test_r2:.3f}\")\n",
    "    print(f\"MAE = {train_mae:.2f}\\t\\t\\t\\t\\tMAE = {test_mae:.2f}\")\n",
    "    results.loc[description]= (train_r2, val_r2, test_r2, train_mae, test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comenzaremos con un modelo sencillo de regresión lineal de Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "phospho_pipe_linr = Pipeline([('prep', phospho_trans),\n",
    "                 ('clas', Ridge())])\n",
    "parameters = {'clas__alpha':np.logspace(-4, 4, 9, endpoint=True)}\n",
    "\n",
    "GS = GridSearchCV(phospho_pipe_linr, param_grid=parameters, cv=5)\n",
    "GS.fit(phospho_train, p_ERK_train)\n",
    "        \n",
    "print(\"Mejor score: \", GS.best_score_)\n",
    "print(\"Mejore configuración de parámetros: \", GS.best_params_)\n",
    "\n",
    "ridge_ERK = GS.best_estimator_\n",
    "\n",
    "description = 'Ridge regression para ERK'\n",
    "show_results(description, ridge_ERK, phospho_train, p_ERK_train, phospho_test, p_ERK_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar el modelo y los resultados\n",
    "import pickle\n",
    "filename = 'Models/Ridge_ERK.sav'\n",
    "pickle.dump(ridge_ERK, open(filename, 'wb'))\n",
    "results.to_csv(\"results.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "phospho_pipe_dect = Pipeline([('prep', phospho_trans),\n",
    "                 ('clas', DecisionTreeRegressor())])\n",
    "parameters = {'clas__max_depth':np.linspace(1,15,15), 'clas__min_samples_split':(2,4,6,8,10)}\n",
    "GS = GridSearchCV(phospho_pipe_dect, param_grid=parameters, cv=5)\n",
    "GS.fit(phospho_train, p_ERK_train)\n",
    "        \n",
    "print(\"Mejor score: \", GS.best_score_)\n",
    "print(\"Mejore configuración de parámetros: \", GS.best_params_)\n",
    "\n",
    "tree_ERK = GS.best_estimator_\n",
    "description = 'Regression tree for ERK'\n",
    "show_results(description, tree_ERK, phospho_train, p_ERK_train, phospho_test, p_ERK_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar el modelo y los resultados\n",
    "import pickle\n",
    "filename = 'Models/DecTree_ERK.sav'\n",
    "pickle.dump(tree_ERK, open(filename, 'wb'))\n",
    "results.to_csv(\"results.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "phospho_pipe_RF = Pipeline([('prep', phospho_trans),\n",
    "                 ('clas', RandomForestRegressor())])\n",
    "parameters = {'clas__max_depth':[1,5,10,15,20]}\n",
    "GS = GridSearchCV(phospho_pipe_RF, param_grid=parameters, cv=5)\n",
    "GS.fit(phospho_train, p_ERK_train)\n",
    "        \n",
    "print(\"Mejor score: \", GS.best_score_)\n",
    "print(\"Mejore configuración de parámetros: \", GS.best_params_)\n",
    "\n",
    "RF_ERK = GS.best_estimator_\n",
    "description = 'Random forest for ERK'\n",
    "show_results(description, RF_ERK, phospho_train, p_ERK_train, phospho_test, p_ERK_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar el modelo y los resultados\n",
    "import pickle\n",
    "filename = 'Models/RF_ERK.sav'\n",
    "pickle.dump(RF_ERK, open(filename, 'wb'))\n",
    "results.to_csv(\"results.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#función para entrenar y guardar los modelos de Ridge, DecissionTree y RandomForest para cada proteína\n",
    "def train_models(prot, trains, tests, n):\n",
    "    #Ridge\n",
    "    parameters = {'clas__alpha':np.logspace(-4, 4, 5, endpoint=True)}\n",
    "    GS = GridSearchCV(phospho_pipe_linr, param_grid=parameters, cv=5)\n",
    "    GS.fit(phospho_train, trains)\n",
    "    globals()[f\"ridge_{prot}\"] = GS.best_estimator_\n",
    "    description = str('Ridge regression para ' + prot)\n",
    "    show_results(description, globals()[f\"ridge_{prot}\"], phospho_train, trains, phospho_test, tests)\n",
    "    #guardar modelo\n",
    "    filename = str('Models/Ridge_' + prot + '.sav')\n",
    "    pickle.dump(globals()[f\"ridge_{prot}\"], open(filename, 'wb'))\n",
    "    results.to_csv(\"results.csv\")\n",
    "    #Decision tree\n",
    "    parameters = {'clas__max_depth':np.linspace(1,15,15), 'clas__min_samples_split':(2,4,6,8,10)}\n",
    "    GS = GridSearchCV(phospho_pipe_dect, param_grid=parameters, cv=5)\n",
    "    GS.fit(phospho_train, trains)\n",
    "    globals()[f\"tree_{prot}\"] = GS.best_estimator_\n",
    "    description = str('Decission tree para ' + prot)\n",
    "    show_results(description, globals()[f\"tree_{prot}\"], phospho_train, trains, phospho_test, tests)\n",
    "    #guardar modelo\n",
    "    filename = str('Models/DecTree_' + prot + '.sav')\n",
    "    pickle.dump(globals()[f\"tree_{prot}\"], open(filename, 'wb'))\n",
    "    results.to_csv(\"results.csv\")\n",
    "    #Random forest\n",
    "    parameters = {'clas__max_depth':[1,5,10,15,20]}\n",
    "    GS = GridSearchCV(phospho_pipe_RF, param_grid=parameters, cv=5)\n",
    "    GS.fit(phospho_train, trains)\n",
    "    globals()[f\"RF_{prot}\"] = GS.best_estimator_\n",
    "    description = str('Random forest for' + prot)\n",
    "    show_results(description, globals()[f\"RF_{prot}\"], phospho_train, trains, phospho_test, tests)\n",
    "    filename = str('Models/RF_' + prot + '.sav')\n",
    "    pickle.dump(globals()[f\"RF_{prot}\"], open(filename, 'wb'))\n",
    "    results.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.Akt.Ser473. p_AktSer473_train p_AktSer473_test\n",
      "p.S6 p_S6_train p_S6_test\n",
      "p.HER2 p_HER2_train p_HER2_test\n",
      "p.PLCg2 p_PLCg2_train p_PLCg2_test\n"
     ]
    }
   ],
   "source": [
    "#Entrenar los modelos para todas las proteínas\n",
    "proteins=[\"p.Akt.Ser473.\", \"p.S6\", \"p.HER2\", \"p.PLCg2\"]\n",
    "train=[\"p_AktSer473_train\", \"p_S6_train\", \"p_HER2_train\", \"p_PLCg2_train\"]\n",
    "test=[\"p_AktSer473_test\", \"p_S6_test\", \"p_HER2_test\", \"p_PLCg2_test\"]\n",
    "\n",
    "for n in range(4):\n",
    "    train_models(proteins[n], train[n], test[n], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
